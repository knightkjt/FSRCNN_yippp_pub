{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fsrcnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knightkjt/FSRCNN_yippp_pub/blob/master/fsrcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I30YegE02jB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "12efa09a-8cca-4dcd-972d-4c618ce5ae52"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "# mount google drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd7aNb3N1NF1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "42fb5a92-e444-4baa-ec0f-85620bc213fa"
      },
      "source": [
        "!ls gdrive/My\\ Drive\\/Colab\\ Notebooks/FSRCNN/FSRCNN-master"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bmp\t      dataset\t logs\t  main.py  model.py   Report.md\n",
            "butterfly.py  logger.py  loss.py  misc.py  README.md  solver.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhFu8Oqe1oL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp -rf gdrive/My\\ Drive\\/Colab\\ Notebooks/FSRCNN/FSRCNN-master/* .\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EzbZp9mAqHO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "f7e32aab-bf76-4f15-dceb-2381596429bf"
      },
      "source": [
        "def getLocalFiles(path_): \n",
        "    _files = os.listdir(path_)\n",
        "    print (_files)\n",
        "    if len(_files) >0: \n",
        "        for l in _files:\n",
        "            ext = l.lower().split('.')[-1]\n",
        "            k = path_ + l\n",
        "            #print (ext)\n",
        "            if (not os.path.isdir(k) and not ext == 'ipynb'):\n",
        "                #import pdb;pdb.set_trace()\n",
        "                v = open(k,'rb').read()\n",
        "                open(k,'wb').write(v) \n",
        "!ls\n",
        "getLocalFiles('./')   \n",
        "getLocalFiles('./dataset/')\n",
        "        \n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json      dataset\t logs\t  misc.py    Report.md\n",
            "bmp\t      gdrive\t loss.py  model.py   sample_data\n",
            "butterfly.py  logger.py  main.py  README.md  solver.py\n",
            "['.config', 'loss.py', 'misc.py', 'butterfly.py', 'main.py', 'logs', 'adc.json', 'model.py', 'gdrive', 'dataset', 'bmp', 'solver.py', 'Report.md', 'logger.py', 'README.md', 'sample_data']\n",
            "['generate_test.m', 'test', 'img_cut.py', 'train', 'modcrop.m', 'generate_train.m', 'store2hdf5.m', 'PairRandomCrop.py', 'data.py', 'dataset.py', 'data_aug.m']\n",
            "['.config', 'loss.py', 'misc.py', 'butterfly.py', 'main.py', 'logs', 'adc.json', 'model.py', 'gdrive', 'dataset', 'bmp', 'solver.py', 'Report.md', 'logger.py', 'README.md', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yDGsEg1Erh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!touch dataset/__init__.py\n",
        "from dataset.data import *\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UALgBcc_Q0C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "3c1a4053-c578-45c3-e32d-1d9040e365a0"
      },
      "source": [
        "\n",
        "!python main.py --train_set=train/91-images"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===> Loading datasets\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 38, in <module>\n",
            "    main()\n",
            "  File \"main.py\", line 22, in main\n",
            "    train_set = get_h5_set(args.train_set)\n",
            "  File \"/content/dataset/data.py\", line 12, in get_h5_set\n",
            "    return LoadH5(train_dir)\n",
            "  File \"/content/dataset/dataset.py\", line 40, in __init__\n",
            "    with h5py.File(image_h5, 'r') as hf:\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/h5py/_hl/files.py\", line 312, in __init__\n",
            "    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/h5py/_hl/files.py\", line 142, in make_fid\n",
            "    fid = h5f.open(name, flags, fapl=fapl)\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open\n",
            "IOError: Unable to open file (file read failed: time = Sun Aug  4 11:30:27 2019\n",
            ", filename = './dataset/train/91-images', file descriptor = 3, errno = 21, error message = 'Is a directory', buf = 0x7ffe4b976170, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP41QbX0IUCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#------------------------------------------------------------------------------\n",
        "# The famous data set:cats vs dogs is used in this example. The data set contains\n",
        "# 12500 dog pictures and 12500 cat pictures. All the images are shuffled randomly\n",
        "# and 20000 images are used to train, 5000 images are used to test. The images\n",
        "# can be resized to different sizes but the size of the .hdf5 file differs very\n",
        "# far depending on the size of the images. The file is 1.14G when the size of the \n",
        "# images is (128,128) and 4.57G for (256,256), 18.3G for (512,512).\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "########################## first part: prepare data ###########################\n",
        "from random import shuffle\n",
        "import glob\n",
        "\n",
        "shuffle_data = True  # shuffle the addresses\n",
        "\n",
        "hdf5_path = './dataset/train/91.h5'  # file path for the created .hdf5 file\n",
        "\n",
        "train_path = './dataset/train/91-images/*.bmp' # the original data path\n",
        "\n",
        "# get all the image paths \n",
        "addrs = glob.glob(train_path)\n",
        "\n",
        "# label the data as 0=cat, 1=dog\n",
        "#import pdb; pdb.set_trace()\n",
        "#labels = [0 if 'cat' in addr else 1 for addr in addrs] \n",
        "labels = [1 if 't' in addr else 1 for addr in addrs]  \n",
        "\n",
        "# shuffle data\n",
        "if shuffle_data:\n",
        "    c = list(zip(addrs, labels)) # use zip() to bind the images and labels together\n",
        "    shuffle(c)\n",
        " \n",
        "    (addrs, labels) = zip(*c)  # *c is used to separate all the tuples in the list c,  \n",
        "                               # \"addrs\" then contains all the shuffled paths and \n",
        "                               # \"labels\" contains all the shuffled labels.\n",
        "                               \n",
        "# Divide the data into 80% for train and 20% for test\n",
        "train_addrs = addrs[0:int(0.8*len(addrs))]\n",
        "train_labels = labels[0:int(0.8*len(labels))]\n",
        "\n",
        "test_addrs = addrs[int(0.8*len(addrs)):]\n",
        "test_labels = labels[int(0.8*len(labels)):]\n",
        "\n",
        "##################### second part: create the h5py object #####################\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "train_shape = (len(train_addrs), 128, 128, 3)\n",
        "test_shape = (len(test_addrs), 128, 128, 3)\n",
        "\n",
        "# open a hdf5 file and create earrays \n",
        "f = h5py.File(hdf5_path, mode='w')\n",
        "\n",
        "# PIL.Image: the pixels range is 0-255,dtype is uint.\n",
        "# matplotlib: the pixels range is 0-1,dtype is float.\n",
        "f.create_dataset(\"train_img\", train_shape, np.uint8)\n",
        "f.create_dataset(\"test_img\", test_shape, np.uint8)  \n",
        "\n",
        "# the \".create_dataset\" object is like a dictionary, the \"train_labels\" is the key. \n",
        "f.create_dataset(\"train_labels\", (len(train_addrs),), np.uint8)\n",
        "f[\"train_labels\"][...] = train_labels\n",
        "\n",
        "f.create_dataset(\"test_labels\", (len(test_addrs),), np.uint8)\n",
        "f[\"test_labels\"][...] = test_labels\n",
        "\n",
        "######################## third part: write the images #########################\n",
        "import cv2\n",
        "\n",
        "# loop over train paths\n",
        "for i in range(len(train_addrs)):\n",
        "  \n",
        "    if i % 1000 == 0 and i > 1:\n",
        "        print ('Train data: {}/{}'.format(i, len(train_addrs)) )\n",
        "\n",
        "    addr = train_addrs[i]\n",
        "    img = cv2.imread(addr)\n",
        "    img = cv2.resize(img, (128, 128), interpolation=cv2.INTER_CUBIC)# resize to (128,128)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 load images as BGR, convert it to RGB\n",
        "    f[\"train_img\"][i, ...] = img[None] \n",
        "\n",
        "# loop over test paths\n",
        "for i in range(len(test_addrs)):\n",
        "\n",
        "    if i % 1000 == 0 and i > 1:\n",
        "        print ('Test data: {}/{}'.format(i, len(test_addrs)) )\n",
        "\n",
        "    addr = test_addrs[i]\n",
        "    img = cv2.imread(addr)\n",
        "    img = cv2.resize(img, (128, 128), interpolation=cv2.INTER_CUBIC)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    f[\"test_img\"][i, ...] = img[None]\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L53E7PcZJWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}